{"cells":[{"metadata":{"_uuid":"50e875c7c1b7e8c998507d9b2573224593861b9a"},"cell_type":"markdown","source":"# Scene classification"},{"metadata":{"_uuid":"edce220d096f99b124ff0e01d8ba1c4e8a8a01cc"},"cell_type":"markdown","source":"**Import the relevant libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"path = \"../input/scene_classification/scene_classification/train/\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pretrainedmodels\n\nfrom torchvision.models import *\nimport pretrainedmodels\n\nfrom fastai.vision import *\nfrom fastai.vision.models import *\nfrom fastai.vision.learner import model_meta\n\nfrom utils import *\nimport sys","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfee912478cf492fadf22cc800717c1d8fa089db"},"cell_type":"code","source":"bs = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa3bdc3cacf18ff21e7450279cc0ecabf1dc57dd"},"cell_type":"code","source":"df = pd.read_csv('../input/scene_classification/scene_classification/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfilenames = os.listdir('../input/scene_classification/scene_classification/test/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d35d9b01a47db718d86f1df43627b8e93bd18ad2"},"cell_type":"code","source":"tfms = get_transforms(flip_vert=False,max_zoom=1.0,max_warp=0,do_flip=False,xtra_tfms=[cutout()])\ndata = (ImageList.from_csv(path, csv_name = '../train.csv') \n        .split_by_rand_pct()              \n        .label_from_df()            \n        .add_test_folder(test_folder = '../test')              \n        .transform(tfms, size=150)\n        .databunch(num_workers=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d919b4cff4c2c8771e7059acefe74e0f30a80ff","_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(8,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"672f015ee5b2485901cf7ec774125c72a5a33ac1"},"cell_type":"code","source":"print(data.classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"545e7cf0d173a51dfdef958a6cbe5b9a9b6c0736"},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet152, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c5443eadbd87d4a9ade44df6d54fc52eb4d44f8"},"cell_type":"code","source":"learn.fit_one_cycle(6)\nlearn.unfreeze()\nlearn.lr_find()\nlearn.fit_one_cycle(6, max_lr=slice(1e-6, 1e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## resnet101\n# 0\t0.389204\t0.276102\t0.102173\t0.897827\t01:35\n# 1\t0.265536\t0.231576\t0.080446\t0.919554\t01:18\n# 2\t0.219510\t0.204855\t0.070464\t0.929536\t01:18\n# 3\t0.170762\t0.200797\t0.065766\t0.934234\t01:17","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds3,_ = learn.TTA(ds_type=DatasetType.Test)\npred1 = preds3\n\nlabelled_preds = []\nfor pred in pred1:\n    labelled_preds.append(int(np.argmax(pred)))\n\nsubmission = pd.DataFrame(\n    {'image_name': filenames,\n     'label': labelled_preds,\n    })\nsubmission.to_csv('new_submission1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_oof,_ = learn.get_preds(ds_type=DatasetType.Train)\n# DatasetType.Test\ntrain_preds = []\nfor pred in preds_oof:\n    train_preds.append(int(np.argmax(pred)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet152, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")\n\nlearn.fit_one_cycle(6)\n\n# preds2,_ = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds2,_ = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"http://places2.csail.mit.edu/models_places365/resnet18_places365.pth.tar\nlearn11 = cnn_learner(data, models.ResNet, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn1 = cnn_learner(data, models.densenet201, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")\n\n# learn2 = cnn_learner(data, models.resnet152, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")\n\nlearn3 = cnn_learner(data, models.densenet169, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")\n\nlearn4 = cnn_learner(data, models.resnet101, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")\n\nlearn5 = cnn_learner(data, models.densenet121, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")\n\nlearn6 = cnn_learner(data, models.resnet50, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")\n\n# learn1.fit_one_cycle(6)\n# learn2.fit_one_cycle(6)\nlearn3.fit_one_cycle(6, max_lr=slice(1e-6, 1e-4))\nlearn4.fit_one_cycle(6, max_lr=slice(1e-6, 1e-4))\nlearn5.fit_one_cycle(6, max_lr=slice(1e-6, 1e-4))\nlearn6.fit_one_cycle(6, max_lr=slice(1e-6, 1e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds3,_ = learn3.get_preds(ds_type=DatasetType.Test)\n\npreds4,_ = learn4.get_preds(ds_type=DatasetType.Test)\n\npreds5,_ = learn5.get_preds(ds_type=DatasetType.Test)\n\npreds6,_ = learn6.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = 5 * preds1 + 5 * preds2 + 4 * preds3 + 3 * preds4 + 3 * preds5 + 3 * preds6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelled_preds = []\nfor pred1 in pred:\n    labelled_preds.append(int(np.argmax(pred1)))\n\nsubmission = pd.DataFrame(\n    {'image_name': filenames,\n     'label': labelled_preds,\n    })\n\nsubmission.to_csv('new_submission_add.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"926adfe2f169f3ad56628c47305362a23b2cb357"},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5409a1bc4c92c7c47bbbefc74f04b9b34f7caf49","collapsed":true},"cell_type":"code","source":"interp.plot_top_losses(9, figsize=(15,11))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dee36fb7c178a811ca25094485ef8e1e46dc53e","collapsed":true},"cell_type":"code","source":"interp.most_confused(min_val=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d84aca6e8fb7100fff9eb71e4b9e383df24e228"},"cell_type":"code","source":"learn.save('/kaggle/working/stage-1-50-128')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,_ = learn.get_preds(ds_type=DatasetType.Test)\n\nlabelled_preds = []\nfor pred in preds:\n    labelled_preds.append(int(np.argmax(pred)))\n\nsubmission = pd.DataFrame(\n    {'image_name': filenames,\n     'label': labelled_preds,\n    })\n\nsubmission.to_csv('new_submission1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dde475f0bf74c12c2d24e06b1925a19b635a39a"},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5c3db9e7dbb9eae17d0795874a96a9d956074af"},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"732aaf3cb012bf84b758ac6542583495933d14a8"},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"20a7e1cde5a9122c36aaf3a15502f7de32e47830"},"cell_type":"code","source":"learn.fit_one_cycle(7, max_lr=slice(1e-6, 1e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fb38793b4561ae822691049babe78207244236b"},"cell_type":"code","source":"learn.save('/kaggle/working/stage-2-50-128')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,_ = learn.get_preds(ds_type=DatasetType.Test)\n\nlabelled_preds = []\nfor pred in preds:\n    labelled_preds.append(int(np.argmax(pred)))\n\nsubmission = pd.DataFrame(\n    {'image_name': filenames,\n     'label': labelled_preds,\n    })\n\nsubmission.to_csv('new_submission2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"subm.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(submission)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15810e0b260e078aafa3b18ce212f3caf7d8f091"},"cell_type":"markdown","source":"**Changing image resolution to 256**"},{"metadata":{"trusted":true,"_uuid":"652e3d2fae8575839ab420dd791f671d3fcbe957"},"cell_type":"code","source":"tfms = get_transforms(flip_vert=False,max_zoom=1.0,max_warp=0,do_flip=False)\ndata = (ImageList.from_csv(path, csv_name = '../train.csv') \n        .split_by_rand_pct()              \n        .label_from_df()            \n        .add_test_folder(test_folder = '../test')              \n        .transform(tfms, size=300)\n        .databunch(num_workers=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72f1b24d7db4fe05239d5549df1fbcd4bb3556fa"},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(8,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74cec8d01711132595d27093108276073ebd6fba","scrolled":false},"cell_type":"code","source":"learn.load('/kaggle/working/stage-2-50-128')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56d622bbc43334ae75d65d1761c9136c09bd491a"},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"370bef1b90ae8c0b251f58e7c329d4ff06e7292f"},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc206515ebc967ac2d95113278f4006f5b14572e"},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d5e1a4d5ef7e2a3107fcb31f8f1efc6b138c9cc"},"cell_type":"code","source":"learn.fit_one_cycle(7, max_lr=slice(1e-6, 1e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fd5521f6d97f8fd0bd493c9d3d9979e313c4210"},"cell_type":"code","source":"learn.save('/kaggle/working/stage-1-50-256')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f22b4abf64b88a22a9de01ab100a0215f298d7c"},"cell_type":"code","source":"preds,_ = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"162800f15eceb88fed88e2fd4d86080d0c004baf"},"cell_type":"code","source":"labelled_preds = []\nfor pred in preds:\n    labelled_preds.append(int(np.argmax(pred)))\n    \n# labelled_preds[0:10]\nlen(labelled_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74eb936f33c1d46f974b815dc0364c4a53bf980a"},"cell_type":"code","source":"len(filenames) == len(labelled_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c207c8ae9b3975262f6c7893a628cfbd50810921"},"cell_type":"code","source":"submission = pd.DataFrame(\n    {'image_name': filenames,\n     'label': labelled_preds,\n    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6f4d8478add0271a8478d3fbc70cadfb926d929"},"cell_type":"code","source":"submission.to_csv('new_submission3.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45f7b2356d117d8f1e114b2de6382aa3bcf7d61f"},"cell_type":"code","source":"# from IPython.display import FileLinks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b15e8ebf9293c6c4c707ff86a018eeec70d217cc"},"cell_type":"code","source":"# FileLinks('.') # download the files without committing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pretrainedmodels.model_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resnext101_32x4d(pretrained=False):\n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.resnext101_32x4d(pretrained=pretrained)\n    all_layers = list(model.children())\n    return nn.Sequential(*all_layers[0], *all_layers[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# arch_summary(resnext101_32x4d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"learn = create_cnn(data, resnext101_32x4d, pretrained=False,\n                  cut=-2, split_on=lambda m: (m[0][6], m[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pnasnet5large"},{"metadata":{"trusted":true},"cell_type":"code","source":"def identity(x): return x\n\ndef pnasnet5large(pretrained=False):    \n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.pnasnet5large(pretrained=pretrained, num_classes=1000) \n    model.logits = identity\n    return nn.Sequential(model)\n\nmodel_meta[pnasnet5large] =  { 'cut': None, \n                               'split': lambda m: (list(m[0][0].children())[8], m[1]) }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"learn = create_cnn(data, pnasnet5large(), metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Xception"},{"metadata":{"trusted":true},"cell_type":"code","source":"def xception(pretrained=True):\n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.xception(pretrained=pretrained)\n    return nn.Sequential(*list(model.children()))\n\nlearn = create_cnn(data, xception, pretrained=True, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\",\n                  cut=-1, split_on=lambda m: (m[0][11], m[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot()\n\nlearn.fit_one_cycle(6, max_lr=slice(1e-6,1e-4)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,_ = learn.TTA(ds_type=DatasetType.Test)\n# preds1,_ = learn.get_preds(ds_type=DatasetType.Test)\n\n# pred1 = preds + preds1\n\npred1 = preds\n\nlabelled_preds = []\nfor pred in pred1:\n    labelled_preds.append(int(np.argmax(pred)))\n\nsubmission = pd.DataFrame(\n    {'image_name': filenames,\n     'label': labelled_preds,\n    })\n\nsubmission.to_csv('new_submission2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.one_cycle_scheduler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"subm.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# epoch\ttrain_loss\tvalid_loss\terror_rate\taccuracy\ttime\n# 0\t0.266674\t0.184001\t0.061656\t0.938344\t04:05\n# 1\t0.221602\t0.156560\t0.056665\t0.943335\t03:59\n# 2\t0.186194\t0.150860\t0.057546\t0.942455\t03:57\n# 3\t0.157000\t0.134333\t0.047563\t0.952437\t03:57\n# 4\t0.123728\t0.128506\t0.047270\t0.952730\t03:58\n# 5\t0.111995\t0.127972\t0.046389\t0.953611\t03:58","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inception"},{"metadata":{"trusted":true},"cell_type":"code","source":"def inceptionv4(pretrained=True):\n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.inceptionv4(pretrained=pretrained)\n    all_layers = list(model.children())\n    return nn.Sequential(*all_layers[0], *all_layers[1:])\n\nlearn = create_cnn(data, inceptionv4, pretrained=True, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\",\n                   cut=-2, split_on=lambda m: (m[0][11], m[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(3) \nlearn.unfreeze()\nlearn.fit_one_cycle(1, max_lr=slice(1e-6,1e-4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## InceptionResnet"},{"metadata":{"trusted":true},"cell_type":"code","source":"def inceptionresnetv2(pretrained=True):\n    pretrained = 'imagenet' if pretrained else None\n    model11 = pretrainedmodels.inceptionresnetv2(pretrained=pretrained)\n    return nn.Sequential(*model11.children())\n\nlearn = create_cnn(data, inceptionresnetv2, pretrained=True, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\",\n                   cut=-2, split_on=lambda m: (m[0][9], m[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model11 = pretrainedmodels.inceptionresnetv2(pretrained='imagenet')\naa = nn.Sequential(*model11.children())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aa","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#'http://places2.csail.mit.edu/models_places365/resnet18_places365.pth.tar'\ndef inceptionresnetv2(pretrained=True):\n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.resnet18(pretrained=pretrained)\n#     model = resnet18(pretrained=pretrained)\n    return nn.Sequential(*model.children())\n\nlearn = create_cnn(data, inceptionresnetv2, pretrained=True, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\",\n                   cut=-2, split_on=lambda m: (m[0][6], m[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arch = 'resnet18'\n\n# load the pre-trained weights\nmodel_file = '%s_places365.pth.tar' % arch\nif not os.access(model_file, os.W_OK):\n    weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n    os.system('wget ' + weight_url)\n\nmodel1 = models.__dict__[arch](num_classes=365)\ncheckpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\nstate_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\nmodel1.load_state_dict(state_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#'http://places2.csail.mit.edu/models_places365/resnet18_places365.pth.tar'\ndef inceptionresnetv21( pretrained=True):\n    pretrained = 'imagenet' if pretrained else None\n#     model = pretrainedmodels.resnet18(pretrained=pretrained)\n#     arch = 'alexnet'\n    arch = 'resnet50'\n    # load the pre-trained weights\n    model_file = '%s_places365.pth.tar' % arch\n    if not os.access(model_file, os.W_OK):\n        weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n        os.system('wget ' + weight_url)\n\n    model = models.__dict__[arch](num_classes=365)\n    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n    model.load_state_dict(state_dict)\n    return nn.Sequential(*model.children())\n\nlearn = create_cnn(data, inceptionresnetv21, pretrained=True, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\",\n                   cut=-2, split_on=lambda m: (m[0][6], m[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms = get_transforms(flip_vert=False,max_zoom=1.0,max_warp=0)\ndata = (ImageList.from_csv(path, csv_name = '../train.csv') \n        .split_by_rand_pct()              \n        .label_from_df()            \n        .add_test_folder(test_folder = '../test')              \n        .transform(tfms, size=150)\n        .databunch(num_workers=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inceptionresnetv11( pretrained=True):\n    pretrained = 'imagenet' if pretrained else None\n    arch = 'resnet18'\n    model_file = '%s_places365.pth.tar' % arch\n    if not os.access(model_file, os.W_OK):\n        weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n        os.system('wget ' + weight_url)\n\n    model = models.__dict__[arch](num_classes=365)\n    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n    model.load_state_dict(state_dict)\n    return nn.Sequential(*model.children())\n\nlearn1 = create_cnn(data, inceptionresnetv11, pretrained=True, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\",\n                   cut=-2, split_on=lambda m: (m[0][6], m[1]))\n\ndef inceptionresnetv12( pretrained=True):\n    pretrained = 'imagenet' if pretrained else None\n    arch = 'resnet50'\n    model_file = '%s_places365.pth.tar' % arch\n    if not os.access(model_file, os.W_OK):\n        weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n        os.system('wget ' + weight_url)\n    model = models.__dict__[arch](num_classes=365)\n    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n    model.load_state_dict(state_dict)\n    return nn.Sequential(*model.children())\n\nlearn2 = create_cnn(data, inceptionresnetv12, pretrained=True, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\",\n                   cut=-2, split_on=lambda m: (m[0][6], m[1]))\n\ndef inceptionresnetv13( pretrained=True):\n    pretrained = 'imagenet' if pretrained else None\n#     model = pretrainedmodels.resnet18(pretrained=pretrained)\n    arch = 'alexnet'\n    model_file = '%s_places365.pth.tar' % arch\n    if not os.access(model_file, os.W_OK):\n        weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n        os.system('wget ' + weight_url)\n    model = models.__dict__[arch](num_classes=365)\n    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n    model.load_state_dict(state_dict)\n    return nn.Sequential(*model.children())\n\nlearn3 = create_cnn(data, inceptionresnetv13, pretrained=True, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\",\n                   cut=-2, split_on=lambda m: (m[0][0][6], m[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn2.fit_one_cycle(6) \nlearn2.unfreeze()\nlearn2.lr_find()\nlearn2.fit_one_cycle(6, max_lr=slice(1e-6,1e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn1.fit_one_cycle(6) \nlearn1.unfreeze()\nlearn1.lr_find()\nlearn1.fit_one_cycle(6, max_lr=slice(1e-6,1e-4)) \n\n# learn2.fit_one_cycle(3) \n# learn2.unfreeze()\n# learn2.lr_find()\n# learn2.fit_one_cycle(6, max_lr=slice(1e-6,1e-4)) \n\n# learn3.fit_one_cycle(3) \n# learn3.unfreeze()\n# learn3.lr_find()\n# learn3.fit_one_cycle(6, max_lr=slice(1e-6,1e-4)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds2,_ = learn2.TTA(ds_type=DatasetType.Test)\n\n# preds1,_ = learn1.TTA(ds_type=DatasetType.Test)\n\npred1 = preds2 + preds1\n\nlabelled_preds = []\nfor pred in pred1:\n    labelled_preds.append(int(np.argmax(pred)))\n\nsubmission = pd.DataFrame(\n    {'image_name': filenames,\n     'label': labelled_preds,\n    })\nsubmission.to_csv('new_submission1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1,_ = learn1.TTA(ds_type=DatasetType.Test)\npreds2,_ = learn2.TTA(ds_type=DatasetType.Test)\npreds3,_ = learn3.TTA(ds_type=DatasetType.Test)\n\npred1 = preds1 + preds2 + preds3\n\nlabelled_preds = []\nfor pred in pred1:\n    labelled_preds.append(int(np.argmax(pred)))\n\nsubmission = pd.DataFrame(\n    {'image_name': filenames,\n     'label': labelled_preds,\n    })\nsubmission.to_csv('new_submission1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms = get_transforms(flip_vert=False,max_zoom=1.0,do_flip=False,max_warp=0,xtra_tfms=[cutout()])\ndata = (ImageList.from_csv(path, csv_name = '../train.csv') \n        .split_by_rand_pct()              \n        .label_from_df()            \n        .add_test_folder(test_folder = '../test')              \n        .transform(tfms, size=300)\n        .databunch(num_workers=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inceptionresnetv14( pretrained=True):\n    pretrained = 'imagenet' if pretrained else None\n    arch = 'resnet18'\n    model_file = '%s_places365.pth.tar' % arch\n    if not os.access(model_file, os.W_OK):\n        weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n        os.system('wget ' + weight_url)\n\n    model = models.__dict__[arch](num_classes=365)\n    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n    model.load_state_dict(state_dict)\n    return nn.Sequential(*model.children())\n\nlearn4 = create_cnn(data, inceptionresnetv14, pretrained=True, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\",\n                   cut=-2, split_on=lambda m: (m[0][6], m[1]))\n\ndef inceptionresnetv15( pretrained=True):\n    pretrained = 'imagenet' if pretrained else None\n    arch = 'resnet50'\n    model_file = '%s_places365.pth.tar' % arch\n    if not os.access(model_file, os.W_OK):\n        weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n        os.system('wget ' + weight_url)\n    model = models.__dict__[arch](num_classes=365)\n    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n    model.load_state_dict(state_dict)\n    return nn.Sequential(*model.children())\n\nlearn5 = create_cnn(data, inceptionresnetv15, pretrained=True, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\",\n                   cut=-2, split_on=lambda m: (m[0][6], m[1]))\n\ndef inceptionresnetv16( pretrained=True):\n    pretrained = 'imagenet' if pretrained else None\n#     model = pretrainedmodels.resnet18(pretrained=pretrained)\n    arch = 'alexnet'\n    model_file = '%s_places365.pth.tar' % arch\n    if not os.access(model_file, os.W_OK):\n        weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n        os.system('wget ' + weight_url)\n    model = models.__dict__[arch](num_classes=365)\n    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n    model.load_state_dict(state_dict)\n    return nn.Sequential(*model.children())\n\nlearn6 = create_cnn(data, inceptionresnetv16, pretrained=True, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\",\n                   cut=-2, split_on=lambda m: (m[0][0][6], m[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn4.fit_one_cycle(6) \nlearn4.unfreeze()\nlearn4.lr_find()\nlearn4.fit_one_cycle(6, max_lr=slice(1e-6,1e-4)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn5.fit_one_cycle(6)\nlearn5.unfreeze()\nlearn5.lr_find()\nlearn5.fit_one_cycle(6, max_lr=slice(1e-6,1e-4))\n\n# learn6.fit_one_cycle(3) \n# learn6.unfreeze()\n# learn6.lr_find()\n# learn6.fit_one_cycle(6, max_lr=slice(1e-6,1e-4)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds4,_ = learn4.TTA(ds_type=DatasetType.Test)\npreds5,_ = learn5.TTA(ds_type=DatasetType.Test)\n# preds6,_ = learn6.TTA(ds_type=DatasetType.Test)\n\npred1 = preds5\n\n# pred1 = preds4 + preds5 + preds6\n\nlabelled_preds = []\nfor pred in pred1:\n    labelled_preds.append(int(np.argmax(pred)))\n\nsubmission = pd.DataFrame(\n    {'image_name': filenames,\n     'label': labelled_preds,\n    })\nsubmission.to_csv('new_submission2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1 = preds1 + preds2 + preds3 + preds4 + preds5 + preds6\n\nlabelled_preds = []\nfor pred in pred1:\n    labelled_preds.append(int(np.argmax(pred)))\n\nsubmission = pd.DataFrame(\n    {'image_name': filenames,\n     'label': labelled_preds,\n    })\nsubmission.to_csv('new_submission3.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}