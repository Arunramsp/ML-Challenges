{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royal\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\royal\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from rgf.sklearn import RGFClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.chdir('C:\\\\Users\\\\royal\\\\Downloads\\\\Compressed\\\\flight_predictor_data\\\\oof+test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.chdir('C:\\\\Users\\\\royal\\\\Downloads\\\\Compressed\\\\flight_predictor_data')\n",
    "train=pd.read_csv('weather_data_train.csv')\n",
    "test=pd.read_csv('weather_data_test.csv')\n",
    "train_flt = pd.read_csv('flight_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the output total and labels.\n",
    "train_flt['total']=0\n",
    "for i in range(1,289):\n",
    "    train_flt['total']+=train_flt['Spot'+str(i)+' totalFlights']\n",
    "\n",
    "train_flt['label']=0\n",
    "for i,j in enumerate(train_flt['total']):\n",
    "    if j>=15:\n",
    "        train_flt.loc[i, 'label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=train_flt['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train11 = pd.DataFrame()\n",
    "test11 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##get the difference between top and lowerheight parameters.\n",
    "aa=['Dew Point','Pressure','Temperature','Wind Direction','Wind Speed']\n",
    "hh=['Station1','Station2','Station3','Station4','Station5']\n",
    "for i in aa:\n",
    "    for j in hh:\n",
    "        train11[j+' '+i+' Height Diff']=train[j+' '+i+' Height45']-train[j+' '+i+' Height1']\n",
    "        test11[j+' '+i+' Height Diff']=test[j+' '+i+' Height45']-test[j+' '+i+' Height1']\n",
    "\n",
    "##get the max,min,standard deviation,variance,mean and diff for all the conditions\n",
    "aa=['Dew Point','Pressure','Temperature','Wind Direction','Wind Speed']\n",
    "hh=['Station1','Station2','Station3','Station4','Station5']\n",
    "for i in aa:\n",
    "    for j in hh:\n",
    "        ls=[]\n",
    "        for k in range(1,46):\n",
    "            ls.append(j+' '+i+' Height'+str(k))\n",
    "        train11[j+' '+i+' Height max']=train[ls].max(axis=1)\n",
    "        train11[j+' '+i+' Height min']=train[ls].min(axis=1)\n",
    "        train11[j+' '+i+' Height std']=train[ls].std(axis=1)\n",
    "        train11[j+' '+i+' Height var']=train[ls].var(axis=1)\n",
    "        train11[j+' '+i+' Height var']=train[ls].mean(axis=1)\n",
    "        \n",
    "        test11[j+' '+i+' Height var']=test[ls].mean(axis=1)\n",
    "        test11[j+' '+i+' Height var']=test[ls].var(axis=1)\n",
    "        test11[j+' '+i+' Height std']=test[ls].std(axis=1)\n",
    "        test11[j+' '+i+' Height max']=test[ls].max(axis=1)\n",
    "        test11[j+' '+i+' Height min']=test[ls].min(axis=1)\n",
    "        \n",
    "        train11[j+' '+i+' Height max-min']=train11[j+' '+i+' Height max']-train11[j+' '+i+' Height min']\n",
    "        test11[j+' '+i+' Height max-min']=test11[j+' '+i+' Height max']-test11[j+' '+i+' Height min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##test and train binary predictions\n",
    "##test\n",
    "os.chdir('C:\\\\Users\\\\royal\\\\Downloads\\\\Compressed\\\\flight_predictor_data\\\\oof+test')\n",
    "cat_test = pd.read_csv('bin_cat_1150d_0.76519_test.csv')\n",
    "ext_test = pd.read_csv('bin_extra_0.77593_test.csv')\n",
    "ext1455_test = pd.read_csv('bin_extra_1455d_0.77927_test.csv')\n",
    "ext251_test = pd.read_csv('bin_extra_251d_0.77202_test.csv')\n",
    "lgb1151_test = pd.read_csv('bin_lgb_1151d_0.79085_test.csv')\n",
    "lgb1201_test = pd.read_csv('bin_lgb_1201d_0.79777_test.csv')\n",
    "lgb225_test = pd.read_csv('bin_lgb_225d_0.78732_test.csv')\n",
    "lgbaae_test = pd.read_csv('bin_lgb_aae_0.78894_test.csv')\n",
    "lgbpca_test = pd.read_csv('bin_lgb_pca_0.77974_test.csv')\n",
    "lr_test = pd.read_csv('bin_lr_225d_0.77011_test.csv')\n",
    "nnaae_test = pd.read_csv('bin_nn_aae_0.75009_test.csv')\n",
    "rgf225_test = pd.read_csv('bin_rgf_225d_0.74622_test.csv')\n",
    "\n",
    "xgb1450_test = pd.read_csv('bin_xgb_1450d_0.79268_test.csv')\n",
    "xgbaae_test = pd.read_csv('bin_xgb_aae_0.79059_test.csv')\n",
    "xgbtune_test = pd.read_csv('bin_xgb_tune_0.79425_test.csv')\n",
    "stac_test = pd.read_csv('submission_stack_152.csv')\n",
    "\n",
    "##train \n",
    "cat_train = pd.read_csv('bin_cat_1150d_0.76519_train.csv')\n",
    "ext_train = pd.read_csv('bin_extra_0.77593_train.csv')\n",
    "ext1455_train = pd.read_csv('bin_extra_1455d_0.77927_train.csv')\n",
    "ext251_train = pd.read_csv('bin_extra_251d_0.77202_train.csv')\n",
    "lgb1151_train = pd.read_csv('bin_lgb_1151d_0.79085_train.csv')\n",
    "lgb1201_train = pd.read_csv('bin_lgb_1201d_0.79777_train.csv')\n",
    "lgb225_train = pd.read_csv('bin_lgb_225d_0.78732_train.csv')\n",
    "lgbaae_train = pd.read_csv('bin_lgb_aae_0.78894_train.csv')\n",
    "lgbpca_train = pd.read_csv('bin_lgb_pca_0.77974_train.csv')\n",
    "lr_train = pd.read_csv('bin_lr_225d_0.77011_train.csv')\n",
    "nnaae_train = pd.read_csv('bin_nn_aae_0.75009_train.csv')\n",
    "rgf225_train = pd.read_csv('bin_rgf_225d_0.74622_train.csv')\n",
    "xgb1450_train = pd.read_csv('bin_xgb_1450d_0.79268_train.csv')\n",
    "xgbaae_train = pd.read_csv('bin_xgb_aae_0.79059_train.csv')\n",
    "xgbtune_train = pd.read_csv('bin_xgb_tune_0.79425_train.csv')\n",
    "sub_146 = pd.read_csv('submission_146.csv')\n",
    "\n",
    "ts_PERID = cat_test['Day_Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##test and train probability predictions\n",
    "##test\n",
    "os.chdir('C:\\\\Users\\\\royal\\\\Downloads\\\\Compressed\\\\flight_predictor_data\\\\oof+test')\n",
    "cat_test = pd.read_csv('prob_cat_1150d_0.76519_test.csv')\n",
    "ext_test = pd.read_csv('prob_extra_0.77593_test.csv')\n",
    "ext1455_test = pd.read_csv('prob_extra_1455d_0.77927_test.csv')\n",
    "ext251_test = pd.read_csv('prob_extra_251d_0.77202_test.csv')\n",
    "lgb1151_test = pd.read_csv('prob_lgb_1151d_0.79085_test.csv')\n",
    "lgb225_test = pd.read_csv('prob_lgb_225d_0.78732_test.csv')\n",
    "lgbaae_test = pd.read_csv('prob_lgb_aae_0.78894_test.csv')\n",
    "lr_test = pd.read_csv('prob_lr_225d_0.77011_test.csv')\n",
    "nnaae_test = pd.read_csv('prob_nn_aae_0.75009_test.csv')\n",
    "rgf225_test = pd.read_csv('prob_rgf_225d_0.74622_test.csv')\n",
    "xgb1450_test = pd.read_csv('prob_xgb_1450d_0.79268_test.csv')\n",
    "xgbaae_test = pd.read_csv('prob_xgb_aae_0.79059_test.csv')\n",
    "xgbtune_test = pd.read_csv('prob_xgb_tune_0.79425_test.csv')\n",
    "\n",
    "##train \n",
    "cat_train = pd.read_csv('prob_cat_1150d_0.76519_train.csv')\n",
    "ext_train = pd.read_csv('prob_extra_0.77593_train.csv')\n",
    "ext1455_train = pd.read_csv('prob_extra_1455d_0.77927_train.csv')\n",
    "ext251_train = pd.read_csv('prob_extra_251d_0.77202_train.csv')\n",
    "lgb1151_train = pd.read_csv('prob_lgb_1151d_0.79085_train.csv')\n",
    "lgb225_train = pd.read_csv('prob_lgb_225d_0.78732_train.csv')\n",
    "lgbaae_train = pd.read_csv('prob_lgb_aae_0.78894_train.csv')\n",
    "lr_train = pd.read_csv('prob_lr_225d_0.77011_train.csv')\n",
    "nnaae_train = pd.read_csv('prob_nn_aae_0.75009_train.csv')\n",
    "rgf225_train = pd.read_csv('prob_rgf_225d_0.74622_train.csv')\n",
    "xgb1450_train = pd.read_csv('prob_xgb_1450d_0.79268_train.csv')\n",
    "xgbaae_train = pd.read_csv('prob_xgb_aae_0.79059_train.csv')\n",
    "xgbtune_train = pd.read_csv('prob_xgb_tune_0.79425_train.csv')\n",
    "\n",
    "ts_PERID = cat_test['Day_Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##average blend. \n",
    "preds1=(ext_test['Good_Bad']+lgbpca_test['Good_Bad']+xgb1450_test['Good_Bad']+lgb1151_test['Good_Bad'])/4\n",
    "\n",
    "prediction_rfc=list(range(len(preds1)))\n",
    "for i in range(len(preds1)):\n",
    "    prediction_rfc[i]=1 if preds1[i]>=0.25 else 0\n",
    "\n",
    "sub = pd.DataFrame({'Day_Id': ts_PERID, 'Good_Bad': prediction_rfc})\n",
    "sub=sub.reindex(columns=[\"Day_Id\",\"Good_Bad\"])\n",
    "filename = 'submission.csv'\n",
    "sub.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 0 1\n",
      "380 1 0\n",
      "908 0 1\n",
      "1335 1 0\n",
      "1586 1 0\n",
      "1711 1 0\n",
      "1940 1 0\n",
      "2300 1 0\n"
     ]
    }
   ],
   "source": [
    "for k,i,j in zip(cat_test['Day_Id'],lgbpca_test['Good_Bad'],lgb1151_test['Good_Bad']):\n",
    "    if i!=j:\n",
    "        print(k,i,j)\n",
    "#         ext_test.loc[ext_test['Day_Id'] == k, 'Good_Bad'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "49 51\n"
     ]
    }
   ],
   "source": [
    "#number of 0 and 1 prediction in the binary file.\n",
    "su = ext1455_test\n",
    "print(set(su['Good_Bad']))\n",
    "prediction_rfc=list(range(len(su['Good_Bad'])))\n",
    "i0=0\n",
    "i1=0\n",
    "for j,i in enumerate(su['Good_Bad']):\n",
    "    if i==0:\n",
    "        prediction_rfc[j]=0\n",
    "        i0=i0+1\n",
    "    else:\n",
    "        i1=i1+1\n",
    "        prediction_rfc[j]=1\n",
    "print(i0,i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# aa=[369,379,1335,1940,1960] #0\n",
    "# bb=[908,1781] #1\n",
    "# aa=[1940,1960,908,1781,216,1931]\n",
    "# bb=[1335,379]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "su = lgbpca_test\n",
    "for k,i in zip(cat_test['Day_Id'],su['Good_Bad']):\n",
    "    if k in aa:\n",
    "        su.loc[su['Day_Id'] == k, 'Good_Bad'] = 0\n",
    "    if k in bb:\n",
    "        su.loc[su['Day_Id'] == k, 'Good_Bad'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'subm.csv'\n",
    "su.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8070413941267186"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##correlation between 2 files.\n",
    "corr1[1].corr(corr1[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_day=train['Day_Id']\n",
    "train1=train.drop(['Day_Id'],axis=1)\n",
    "train1=train1.values\n",
    "Y=train_flt['label'].values\n",
    "\n",
    "test_day=test['Day_Id']\n",
    "test1=test.drop(['Day_Id'],axis=1)\n",
    "test1=test1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stack level1 predictions\n",
    "X_ts=np.column_stack((cat_test['Good_Bad'],ext_test['Good_Bad'],ext1455_test['Good_Bad'],lgb1151_test['Good_Bad'],lgb225_test['Good_Bad'],lr_test['Good_Bad'],nnaae_test['Good_Bad'],rgf225_test['Good_Bad'],xgb1450_test['Good_Bad'],xgbaae_test['Good_Bad'],xgbtune_test['Good_Bad']))\n",
    "X_tr=np.column_stack((cat_train['Good_Bad'],ext_train['Good_Bad'],ext1455_train['Good_Bad'],lgb1151_train['Good_Bad'],lgb225_train['Good_Bad'],lr_train['Good_Bad'],nnaae_train['Good_Bad'],rgf225_train['Good_Bad'],xgb1450_train['Good_Bad'],xgbaae_train['Good_Bad'],xgbtune_train['Good_Bad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr1=np.column_stack((X_tr,train11.values,train1))\n",
    "X_ts1=np.column_stack((X_ts,test11.values,test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 11)\n",
      "(2183, 1286)\n",
      "(2183, 150)\n",
      "(100, 150)\n"
     ]
    }
   ],
   "source": [
    "print(X_ts.shape)\n",
    "print(X_tr1.shape)\n",
    "print(train11.shape)\n",
    "print(test11.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(437,)\n",
      "fold 0, ROC AUC: 0.807\n",
      "(437,)\n",
      "fold 1, ROC AUC: 0.785\n",
      "(437,)\n",
      "fold 2, ROC AUC: 0.808\n",
      "(437,)\n",
      "fold 3, ROC AUC: 0.779\n",
      "(435,)\n",
      "fold 4, ROC AUC: 0.781\n",
      "0.7914202003610796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "SEED=42\n",
    "clf = lgb.LGBMClassifier()\n",
    "st_train = X_tr1\n",
    "st_test = X_ts1\n",
    "# clf = lgb.LGBMClassifier(max_depth= 10, learning_rate=0.044, n_estimators=255, num_leaves= 17, reg_alpha=1.0824, reg_lambda= 0.0386)\n",
    "# clf=CatBoostClassifier(iterations=50)\n",
    "# clf = XGBClassifier()\n",
    "# clf=ExtraTreesClassifier(n_estimators=10000, criterion='entropy', max_depth=9,  min_samples_leaf=1,  n_jobs=30, random_state=1)\n",
    "# clf = XGBClassifier(gamma = 1.0,learning_rate = 0.010,max_depth = 5,min_child_weight = 10,n_estimators = 338,subsample = 0.800,colsample_bytree = 0.50)\n",
    "# clf = RGFClassifier(max_leaf=500,algorithm=\"RGF\",test_interval=100, loss=\"LS\")\n",
    "# clf = LogisticRegression()\n",
    "\n",
    "fold = 5\n",
    "cv = StratifiedKFold(Y, n_folds=fold,shuffle=True, random_state=42)\n",
    "X_preds = np.zeros(st_train.shape[0])\n",
    "preds = np.zeros(st_test.shape[0])\n",
    "for i, (tr, ts) in enumerate(cv):\n",
    "    print(ts.shape)\n",
    "    mod = clf.fit(st_train[tr], Y[tr])\n",
    "    X_preds[ts] = mod.predict_proba(st_train[ts])[:,1]\n",
    "    preds += mod.predict_proba(st_test)[:,1]\n",
    "    print(\"fold {}, ROC AUC: {:.3f}\".format(i, roc_auc_score(Y[ts], X_preds[ts])))\n",
    "score = roc_auc_score(Y, X_preds)\n",
    "print(score)\n",
    "preds1 = preds/fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7301163632835377\n",
      "0.35000000000000003\n"
     ]
    }
   ],
   "source": [
    "# pick the best threshold out-of-fold\n",
    "thresholds = np.linspace(0.01, 0.99, 50)\n",
    "mcc = np.array([roc_auc_score(Y, X_preds>thr) for thr in thresholds])\n",
    "best_threshold = thresholds[mcc.argmax()]\n",
    "print(mcc.max())\n",
    "print(best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction file generation\n",
    "prediction_rfc=list(range(len(preds1)))\n",
    "for i in range(len(preds1)):\n",
    "    prediction_rfc[i]=1 if preds1[i]>best_threshold else 0\n",
    "\n",
    "sub = pd.DataFrame({'Day_Id': ts_PERID, 'Good_Bad': prediction_rfc})\n",
    "sub=sub.reindex(columns=[\"Day_Id\",\"Good_Bad\"])\n",
    "filename = 'submission_stack.csv'\n",
    "sub.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
