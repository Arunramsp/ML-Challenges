{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.models import load_model\n",
    "from keras.initializers import glorot_normal, Zeros, Ones\n",
    "import keras.backend as K\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/keras-team/keras-contrib.git\r\n",
      "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-ubm1nc3_\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.6/site-packages (from keras-contrib==2.0.8) (2.2.4)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.0.9)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.0.7)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (3.12)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.12.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.16.2)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (2.9.0)\r\n",
      "Building wheels for collected packages: keras-contrib\r\n",
      "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-jetdfiw_/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\r\n",
      "Successfully built keras-contrib\r\n",
      "Installing collected packages: keras-contrib\r\n",
      "Successfully installed keras-contrib-2.0.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 300 ms, sys: 80 ms, total: 380 ms\n",
      "Wall time: 407 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/innoplexus/train_3pirksi/train.csv')\n",
    "test = pd.read_csv('../input/innoplexus/test_xev14ad/test.csv')\n",
    "subm = pd.read_csv('../input/innoplexus/sample_submission_usrypcc/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(method=\"ffill\")\n",
    "test = test.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle-Income</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Doc_ID  Sent_ID           Word tag\n",
       "0   1       1        1        Obesity   O\n",
       "1   2       1        1             in   O\n",
       "2   3       1        1           Low-   O\n",
       "3   4       1        1            and   O\n",
       "4   5       1        1  Middle-Income   O"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184506"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(train[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(train[\"tag\"].values))\n",
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sent_ID\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[self.n_sent]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191282"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getter = SentenceGetter(train)\n",
    "sentences = getter.sentences\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([184502, 116761, 182119,  31898, 117943,  26521, 172679,  70356,\n",
       "       119645,  65130, 119645,  31898,  37017, 134375, 105930, 184505,\n",
       "       184505, 184505, 184505, 184505, 184505, 184505, 184505, 184505,\n",
       "       184505, 184505, 184505, 184505, 184505, 184505, 184505, 184505,\n",
       "       184505, 184505, 184505, 184505, 184505, 184505, 184505, 184505,\n",
       "       184505, 184505, 184505, 184505, 184505, 184505, 184505, 184505,\n",
       "       184505, 184505], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words + 1, output_dim=20,\n",
    "                  input_length=max_len, mask_zero=True)(input)  # 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags)  # CRF layer\n",
    "out = crf(model)  # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 154937 samples, validate on 17216 samples\n",
      "Epoch 1/2\n",
      "154937/154937 [==============================] - 498s 3ms/step - loss: 0.0226 - crf_viterbi_accuracy: 0.9914 - val_loss: 0.0124 - val_crf_viterbi_accuracy: 0.9942\n",
      "Epoch 2/2\n",
      " 34016/154937 [=====>........................] - ETA: 6:15 - loss: 0.0114 - crf_viterbi_accuracy: 0.9943"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=2,\n",
    "                    validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19129/19129 [==============================] - 13s 675us/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(X_te, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 64.1%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "indications       0.74      0.57      0.64      5189\n",
      "\n",
      "avg / total       0.74      0.57      0.64      5189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetterTest(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 191283\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w) for w in s[\"Word\"].values.tolist()]\n",
    "        self.grouped = self.data.groupby(\"Sent_ID\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[self.n_sent]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testgetter = SentenceGetterTest(test)\n",
    "test_sentence = testgetter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sent  = pad_sequences(maxlen=max_len, sequences= [[word2idx.get(w, 0) for w in s] for s in test_sentence], padding=\"post\", value=n_words - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n"
     ]
    }
   ],
   "source": [
    "# words = []\n",
    "predss=[]\n",
    "for i in range(len(x_test_sent)):\n",
    "    if i%10000 ==0:\n",
    "        print(i)\n",
    "    idxs = i\n",
    "    p = model.predict(np.array([x_test_sent[idxs]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    #print(test_sentence[idxs])\n",
    "#     print(tags[p[0]])\n",
    "    for w, pred in zip(test_sentence[idxs], p[0]):\n",
    "        #print(w, tags[pred])\n",
    "#         words.append(w)\n",
    "        predss.append(tags[pred])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184506"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2909818"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2994463, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)\n",
    "len(predss)\n",
    "subm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predss.extend(subm['tag'][len(predss):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2994463"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2994463, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predss)\n",
    "subm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm['tag']=predss\n",
    "subm.to_csv('submission_nn.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the modules we'll need\n",
    "# from IPython.display import HTML\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import base64\n",
    "\n",
    "# # function that takes in a dataframe and creates a text link to  \n",
    "# # download it (will only work for files < 2MB or so)\n",
    "# def create_download_link(df, title = \"Download CSV file\", filename = \"out.csv\"):  \n",
    "#     csv = df.to_csv(index=False)\n",
    "#     b64 = base64.b64encode(csv.encode())\n",
    "#     payload = b64.decode()\n",
    "#     html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "#     html = html.format(payload=payload,title=title,filename=filename)\n",
    "#     return HTML(html)\n",
    "\n",
    "# # create a random sample dataframe\n",
    "# df = pd.DataFrame(pred, columns=['tag'])\n",
    "\n",
    "# # create a link to download the dataframe\n",
    "# create_download_link(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O                2840115\n",
       "I-indications     129223\n",
       "B-indications      25125\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANAGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/Hironsan/anago.git\r\n",
      "  Cloning https://www.github.com/Hironsan/anago.git to /tmp/pip-req-build-zcbfg336\r\n",
      "Requirement already satisfied: Keras>=2.2.0 in /opt/conda/lib/python3.6/site-packages (from anago==1.0.8) (2.2.4)\r\n",
      "Requirement already satisfied: h5py>=2.7.1 in /opt/conda/lib/python3.6/site-packages (from anago==1.0.8) (2.9.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from anago==1.0.8) (0.20.3)\r\n",
      "Requirement already satisfied: numpy>=1.14.3 in /opt/conda/lib/python3.6/site-packages (from anago==1.0.8) (1.16.2)\r\n",
      "Requirement already satisfied: tensorflow>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from anago==1.0.8) (1.13.1)\r\n",
      "Requirement already satisfied: requests>=2.18.4 in /opt/conda/lib/python3.6/site-packages (from anago==1.0.8) (2.21.0)\r\n",
      "Requirement already satisfied: seqeval>=0.0.3 in /opt/conda/lib/python3.6/site-packages (from anago==1.0.8) (0.0.6)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.0->anago==1.0.8) (1.0.7)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.0->anago==1.0.8) (3.12)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.0->anago==1.0.8) (1.12.0)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.0->anago==1.0.8) (1.0.9)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.0->anago==1.0.8) (1.1.0)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow>=1.8.0->anago==1.0.8) (0.31.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow>=1.8.0->anago==1.0.8) (1.13.0)\r\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow>=1.8.0->anago==1.0.8) (1.13.1)\r\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow>=1.8.0->anago==1.0.8) (3.7.0)\r\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow>=1.8.0->anago==1.0.8) (0.7.1)\r\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow>=1.8.0->anago==1.0.8) (0.2.2)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow>=1.8.0->anago==1.0.8) (1.1.0)\r\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow>=1.8.0->anago==1.0.8) (0.7.1)\r\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow>=1.8.0->anago==1.0.8) (1.19.0)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18.4->anago==1.0.8) (3.0.4)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18.4->anago==1.0.8) (2.6)\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18.4->anago==1.0.8) (1.22)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18.4->anago==1.0.8) (2019.3.9)\r\n",
      "Requirement already satisfied: mock>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow>=1.8.0->anago==1.0.8) (2.0.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow>=1.8.0->anago==1.0.8) (0.14.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow>=1.8.0->anago==1.0.8) (3.0.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow>=1.8.0->anago==1.0.8) (39.1.0)\r\n",
      "Requirement already satisfied: pbr>=0.11 in /opt/conda/lib/python3.6/site-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow>=1.8.0->anago==1.0.8) (5.1.3)\r\n",
      "Building wheels for collected packages: anago\r\n",
      "  Building wheel for anago (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-wlosfewn/wheels/23/13/ee/c961bc7c80736d808ed1fe0b763c304c1f94bc18b4775f2fe0\r\n",
      "Successfully built anago\r\n",
      "Installing collected packages: anago\r\n",
      "Successfully installed anago-1.0.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://www.github.com/Hironsan/anago.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting allennlp\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/32/d6d0a93a23763f366df2dbd4e007e45ce4d2ad97e6315506db9da8af7731/allennlp-0.8.2-py3-none-any.whl (5.6MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 5.6MB 7.1MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: unidecode in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.0.23)\r\n",
      "Requirement already satisfied: numpydoc==0.8.0 in /opt/conda/lib/python3.6/site-packages (from allennlp) (0.8.0)\r\n",
      "Requirement already satisfied: tqdm>=4.19 in /opt/conda/lib/python3.6/site-packages (from allennlp) (4.31.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.16.2)\r\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.0.1.post2)\r\n",
      "Collecting overrides (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz\r\n",
      "Collecting flaky (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/02/42/cca66659a786567c8af98587d66d75e7d2b6e65662f8daab75db708ac35b/flaky-3.5.3-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.6/site-packages (from allennlp) (3.5.1)\r\n",
      "Collecting responses>=0.7 (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/5a/b887e89925f1de7890ef298a74438371ed4ed29b33def9e6d02dc6036fd8/responses-0.10.6-py2.py3-none-any.whl\r\n",
      "Collecting conllu==0.11 (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/2c/856344d9b69baf5b374c395b4286626181a80f0c2b2f704914d18a1cea47/conllu-0.11-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: spacy<2.1,>=2.0 in /opt/conda/lib/python3.6/site-packages (from allennlp) (2.0.18)\r\n",
      "Collecting matplotlib==2.2.3 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/59/f235ab21bbe7b7c6570c4abf17ffb893071f4fa3b9cf557b09b60359ad9a/matplotlib-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (12.6MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 12.6MB 2.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from allennlp) (0.20.3)\r\n",
      "Collecting parsimonious==0.8.0 (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/89/32c55944cd30dff856f16859ee325b13c83c260d0c56c0eed511e8063c87/parsimonious-0.8.0.tar.gz\r\n",
      "Collecting jsonnet==0.10.0; sys_platform != \"win32\" (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/83/d49904ee98dd4fbba6a003938e30e76251951c4bdb49628b4f92e5009a42/jsonnet-0.10.0.tar.gz (124kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 35.4MB/s \r\n",
      "\u001b[?25hCollecting tensorboardX==1.2 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/22/43f4f0318f7c68a1000dbb700a353b745584bc2397437832d15ba69ea5f1/tensorboardX-1.2-py2.py3-none-any.whl (44kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 16.6MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: msgpack<0.6.0,>=0.5.6 in /opt/conda/lib/python3.6/site-packages (from allennlp) (0.5.6)\r\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.6/site-packages (from allennlp) (4.4.3)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.1.0)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (from allennlp) (3.2.4)\r\n",
      "Collecting pytz==2017.3 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/7f/e7d1acbd433b929168a4fb4182a2ff3c33653717195a26c1de099ad1ef29/pytz-2017.3-py2.py3-none-any.whl (511kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 21.4MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: flask==1.0.2 in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.0.2)\r\n",
      "Collecting editdistance (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/67/2b1fe72bdd13ee9ec32b97959d7dfbfcd7c0548081d69aaf8493c1e695f9/editdistance-0.5.3-cp36-cp36m-manylinux1_x86_64.whl (178kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 36.3MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.9.118)\r\n",
      "Collecting pytorch-pretrained-bert>=0.6.0 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl (114kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 35.5MB/s \r\n",
      "\u001b[?25hCollecting sqlparse==0.2.4 (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/65/85/20bdd72f4537cf2c4d5d005368d502b2f464ede22982e724a82c86268eda/sqlparse-0.2.4-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from allennlp) (2.9.0)\r\n",
      "Collecting gevent==1.3.6 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/3d/a19fece28ba1b5133cf74bd22a229d77b4d9cc4b24aa8f263cca2845c555/gevent-1.3.6-cp36-cp36m-manylinux1_x86_64.whl (4.5MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 4.5MB 6.6MB/s \r\n",
      "\u001b[?25hCollecting moto==1.3.4 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/8f/7b36e81ff067d0e7bf90f7210b351c0cfe6657f79fa4dcb0cb4787462e05/moto-1.3.4-py2.py3-none-any.whl (548kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 29.7MB/s \r\n",
      "\u001b[?25hCollecting flask-cors==3.0.7 (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/65/cb/683f71ff8daa3aea0a5cbb276074de39f9ab66d3fbb8ad5efb5bb83e90d2/Flask_Cors-3.0.7-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: requests>=2.18 in /opt/conda/lib/python3.6/site-packages (from allennlp) (2.21.0)\r\n",
      "Collecting awscli>=1.11.91 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/fe/1dfe7e1cf92a80835086d4e6ac6bcedd4543b74626e3085c23233cae4320/awscli-1.16.130-py2.py3-none-any.whl (1.5MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 18.7MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: sphinx>=1.2.3 in /opt/conda/lib/python3.6/site-packages (from numpydoc==0.8.0->allennlp) (1.7.4)\r\n",
      "Requirement already satisfied: Jinja2>=2.3 in /opt/conda/lib/python3.6/site-packages (from numpydoc==0.8.0->allennlp) (2.10)\r\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from pytest->allennlp) (1.5.3)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from pytest->allennlp) (1.12.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from pytest->allennlp) (39.1.0)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from pytest->allennlp) (18.1.0)\r\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from pytest->allennlp) (4.1.0)\r\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /opt/conda/lib/python3.6/site-packages (from pytest->allennlp) (0.6.0)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.1,>=2.0->allennlp) (1.0.0)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from spacy<2.1,>=2.0->allennlp) (2.0.2)\r\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from spacy<2.1,>=2.0->allennlp) (2.0.1)\r\n",
      "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /opt/conda/lib/python3.6/site-packages (from spacy<2.1,>=2.0->allennlp) (6.12.1)\r\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /opt/conda/lib/python3.6/site-packages (from spacy<2.1,>=2.0->allennlp) (0.9.6)\r\n",
      "Requirement already satisfied: ujson>=1.35 in /opt/conda/lib/python3.6/site-packages (from spacy<2.1,>=2.0->allennlp) (1.35)\r\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /opt/conda/lib/python3.6/site-packages (from spacy<2.1,>=2.0->allennlp) (0.2.9)\r\n",
      "Requirement already satisfied: regex==2018.01.10 in /opt/conda/lib/python3.6/site-packages (from spacy<2.1,>=2.0->allennlp) (2018.1.10)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib==2.2.3->allennlp) (2.6.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib==2.2.3->allennlp) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib==2.2.3->allennlp) (2.2.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib==2.2.3->allennlp) (1.0.1)\r\n",
      "Requirement already satisfied: protobuf>=0.3.2 in /opt/conda/lib/python3.6/site-packages (from tensorboardX==1.2->allennlp) (3.7.0)\r\n",
      "Requirement already satisfied: html5lib in /opt/conda/lib/python3.6/site-packages (from ftfy->allennlp) (1.0.1)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from ftfy->allennlp) (0.1.7)\r\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/lib/python3.6/site-packages (from flask==1.0.2->allennlp) (7.0)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.6/site-packages (from flask==1.0.2->allennlp) (0.24)\r\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /opt/conda/lib/python3.6/site-packages (from flask==1.0.2->allennlp) (0.14.1)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->allennlp) (0.9.4)\r\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.118 in /opt/conda/lib/python3.6/site-packages (from boto3->allennlp) (1.12.118)\r\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->allennlp) (0.2.0)\r\n",
      "Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\" (from gevent==1.3.6->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 22.9MB/s \r\n",
      "\u001b[?25hCollecting pyaml (from moto==1.3.4->allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/e1/1523fb1dab744e2c6b1f02446f2139a78726c18c062a8ddd53875abb20f8/pyaml-18.11.0-py2.py3-none-any.whl\r\n",
      "Collecting xmltodict (from moto==1.3.4->allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\r\n",
      "Collecting jsondiff==1.1.1 (from moto==1.3.4->allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/5f/13e28a2f9abeda2ffb3f44f2f809b01b52bc02cdb63816e05b8c9cbbdfc5/jsondiff-1.1.1.tar.gz\r\n",
      "Collecting cookies (from moto==1.3.4->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/60/557f84aa2db629e5124aa05408b975b1b5d0e1cec16cde0bfa06aae097d3/cookies-2.2.1-py2.py3-none-any.whl (44kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 21.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from moto==1.3.4->allennlp) (2.2.2)\r\n",
      "Requirement already satisfied: mock in /opt/conda/lib/python3.6/site-packages (from moto==1.3.4->allennlp) (2.0.0)\r\n",
      "Collecting python-jose<3.0.0 (from moto==1.3.4->allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/5c/5fa238c0c5b0656994b52721dd8b1d7bf52ebd8786518dde794f44de86b6/python_jose-2.0.2-py2.py3-none-any.whl\r\n",
      "Collecting docker>=2.5.1 (from moto==1.3.4->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/d8/8242b8fb3bd3000274fbf5ac1a06cdba8a5ccbcf4e2a8c05f0ab37999fd8/docker-3.7.1-py2.py3-none-any.whl (134kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 32.3MB/s \r\n",
      "\u001b[?25hCollecting aws-xray-sdk<0.96,>=0.93 (from moto==1.3.4->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/a5/da7887285564f9e0ae5cd25a453cca36e2cd43d8ccc9effde260b4d80904/aws_xray_sdk-0.95-py2.py3-none-any.whl (52kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 22.6MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: boto>=2.36.0 in /opt/conda/lib/python3.6/site-packages (from moto==1.3.4->allennlp) (2.48.0)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18->allennlp) (2.6)\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18->allennlp) (1.22)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18->allennlp) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18->allennlp) (2019.3.9)\r\n",
      "Requirement already satisfied: colorama<=0.3.9,>=0.2.5 in /opt/conda/lib/python3.6/site-packages (from awscli>=1.11.91->allennlp) (0.3.9)\r\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from awscli>=1.11.91->allennlp) (0.14)\r\n",
      "Requirement already satisfied: PyYAML<=3.13,>=3.10 in /opt/conda/lib/python3.6/site-packages (from awscli>=1.11.91->allennlp) (3.12)\r\n",
      "Collecting rsa<=3.5.0,>=3.1.2 (from awscli>=1.11.91->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 21.1MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: Pygments>=2.0 in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (2.2.0)\r\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (1.2.1)\r\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (2.5.3)\r\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (0.7.10)\r\n",
      "Requirement already satisfied: imagesize in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (1.0.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (17.1)\r\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (1.0.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.3->numpydoc==0.8.0->allennlp) (1.0)\r\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in /opt/conda/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy<2.1,>=2.0->allennlp) (0.4.3.2)\r\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /opt/conda/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy<2.1,>=2.0->allennlp) (0.9.0.1)\r\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy<2.1,>=2.0->allennlp) (1.10.11)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from html5lib->ftfy->allennlp) (0.5.1)\r\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.0.0->moto==1.3.4->allennlp) (0.24.0)\r\n",
      "Requirement already satisfied: cffi>=1.7 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.0.0->moto==1.3.4->allennlp) (1.11.5)\r\n",
      "Requirement already satisfied: pbr>=0.11 in /opt/conda/lib/python3.6/site-packages (from mock->moto==1.3.4->allennlp) (5.1.3)\r\n",
      "Requirement already satisfied: future<1.0 in /opt/conda/lib/python3.6/site-packages (from python-jose<3.0.0->moto==1.3.4->allennlp) (0.17.1)\r\n",
      "Collecting pycryptodome<4.0.0,>=3.3.1 (from python-jose<3.0.0->moto==1.3.4->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/cf/4b66bf1ac2484ca39599b4576d681186b61b543c2d2c29f9aa4ba3cc53b5/pycryptodome-3.7.3-cp36-cp36m-manylinux1_x86_64.whl (7.5MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 7.5MB 4.6MB/s \r\n",
      "\u001b[?25hCollecting ecdsa<1.0 (from python-jose<3.0.0->moto==1.3.4->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/f4/73669d51825516ce8c43b816c0a6b64cd6eb71d08b99820c00792cb42222/ecdsa-0.13-py2.py3-none-any.whl (86kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 25.9MB/s \r\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from docker>=2.5.1->moto==1.3.4->allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from docker>=2.5.1->moto==1.3.4->allennlp) (0.55.0)\r\n",
      "Requirement already satisfied: jsonpickle in /opt/conda/lib/python3.6/site-packages (from aws-xray-sdk<0.96,>=0.93->moto==1.3.4->allennlp) (0.9.6)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.6/site-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->allennlp) (0.4.5)\r\n",
      "Requirement already satisfied: toolz>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy<2.1,>=2.0->allennlp) (0.9.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.7->cryptography>=2.0.0->moto==1.3.4->allennlp) (2.18)\r\n",
      "Building wheels for collected packages: overrides, parsimonious, jsonnet, jsondiff\r\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/8d/52/86/e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718\r\n",
      "  Building wheel for parsimonious (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/bb/51/82/ae9b22a790f11e7be918939d01aa397c545ebb3723453c5fb4\r\n",
      "  Building wheel for jsonnet (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/a0/aa/f0/b4ab8854cf00f922a87787425cfbb789aac01ab2c2cd1b4ca4\r\n",
      "  Building wheel for jsondiff (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/68/08/07/69d839606fb7fdc778fa86476abc0a864693d45969a0c1936c\r\n",
      "Successfully built overrides parsimonious jsonnet jsondiff\r\n",
      "\u001b[31mlime 0.1.1.33 has requirement matplotlib==2.1.0, but you'll have matplotlib 2.2.3 which is incompatible.\u001b[0m\r\n",
      "\u001b[31manaconda-client 1.6.14 has requirement python-dateutil>=2.6.1, but you'll have python-dateutil 2.6.0 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mawscli 1.16.130 has requirement botocore==1.12.120, but you'll have botocore 1.12.118 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: overrides, flaky, responses, conllu, pytz, matplotlib, parsimonious, jsonnet, tensorboardX, editdistance, pytorch-pretrained-bert, sqlparse, greenlet, gevent, pyaml, xmltodict, jsondiff, cookies, pycryptodome, ecdsa, python-jose, docker-pycreds, docker, aws-xray-sdk, moto, flask-cors, rsa, awscli, allennlp\r\n",
      "  Found existing installation: pytz 2018.4\r\n",
      "    Uninstalling pytz-2018.4:\r\n",
      "      Successfully uninstalled pytz-2018.4\r\n",
      "  Found existing installation: matplotlib 3.0.3\r\n",
      "    Uninstalling matplotlib-3.0.3:\r\n",
      "      Successfully uninstalled matplotlib-3.0.3\r\n",
      "  Found existing installation: tensorboardX 1.6\r\n",
      "    Uninstalling tensorboardX-1.6:\r\n",
      "      Successfully uninstalled tensorboardX-1.6\r\n",
      "  Found existing installation: greenlet 0.4.13\r\n",
      "\u001b[31mCannot uninstall 'greenlet'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install allennlp\n",
    "# !pip install --ignore-installed allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allennlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-17aca5c26b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0manago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data_and_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mELModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mELMoTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/anago/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0manago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/anago/wrapper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBiLSTMCRF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0manago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndexTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/anago/preprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElmo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_to_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from anago.utils import load_data_and_labels, load_glove, filter_embeddings\n",
    "from anago.models import ELModel\n",
    "from anago.preprocessing import ELMoTransformer\n",
    "from anago.trainer import Trainer\n",
    "\n",
    "p = ELMoTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sent_ID\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[self.n_sent]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(train)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [[w[0] for w in s] for s in sentences]\n",
    "y_train = [[w[1] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-5aff09321b95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "p.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word embeddings...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-6d73275e7114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading word embeddings...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mEMBEDDING_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input/glove6b100dtxt/glove.6B.100d.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_glove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDING_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_word_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_glove' is not defined"
     ]
    }
   ],
   "source": [
    "print('Loading word embeddings...')\n",
    "EMBEDDING_PATH = '../input/glove6b100dtxt/glove.6B.100d.txt'\n",
    "embeddings = load_glove(EMBEDDING_PATH)\n",
    "embeddings = filter_embeddings(embeddings, p._word_vocab.vocab, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ELModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-4b01882b0280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = ELModel(char_embedding_dim=25,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mword_embedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mchar_lstm_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mword_lstm_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mchar_vocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ELModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = ELModel(char_embedding_dim=25,\n",
    "                    word_embedding_dim=100,\n",
    "                    char_lstm_size=25,\n",
    "                    word_lstm_size=100,\n",
    "                    char_vocab_size=p.char_vocab_size,\n",
    "                    word_vocab_size=p.word_vocab_size,\n",
    "                    num_labels=p.label_size,\n",
    "                    embeddings=embeddings,\n",
    "                    dropout=0.5)\n",
    "model, loss = model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b1677501ed86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, preprocessor=p)\n",
    "model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-95a56356b5a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.train(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model...\n"
     ]
    }
   ],
   "source": [
    "print('Saving the model...')\n",
    "model.save('weights.h5', 'params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allennlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-8678c10fef94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp'"
     ]
    }
   ],
   "source": [
    "from allennlp.data import Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
